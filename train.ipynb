{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ASMSA: Train AAE model with the tuned hyperparameters\n",
    "\n",
    "**Previous steps**\n",
    "- [prepare.ipynb](prepare.ipynb): Download and sanity check input files\n",
    "- [tune.ipynb](tune.ipynb): Perform initial hyperparameter tuning for this molecule\n",
    "\n",
    "**Next step**\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 2\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS']=str(threads)\n",
    "import tensorflow as tf\n",
    "\n",
    "# PyTorch favours OMP_NUM_THREADS in environment\n",
    "import torch\n",
    "\n",
    "# Tensorflow needs explicit cofig calls\n",
    "tf.config.threading.set_inter_op_parallelism_threads(threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asmsa.tuning_analyzer import TuningAnalyzer\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "import asmsa.visualizer as visualizer\n",
    "import asmsa\n",
    "\n",
    "\n",
    "from asmsa.plot_training import LiveTrainingPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1c4d1-913f-4fbd-81f5-52860843b617",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Input files\n",
    "\n",
    "All input files are prepared (up- or downloaded) in **prepare.ipynb**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(open('inputs.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load datasets\n",
    "Load filtered trajectory datasets that were processed in **prepare.ipynb**. Trajectories are in internal coordinates format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "X_train = tf.data.Dataset.load('datasets/intcoords/train')\n",
    "\n",
    "# get batched version of dataset to feed to AAE model for training\n",
    "X_train_batched = X_train.batch(hps['batch_size'],drop_remainder=True)\n",
    "\n",
    "# get numpy version for visualization purposes\n",
    "X_train_np = np.stack(list(X_train))\n",
    "X_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "X_test = tf.data.Dataset.load('datasets/intcoords/test')\n",
    "\n",
    "# get batched version of dataset to feed to AAE model for prediction\n",
    "X_test_batched = X_test.batch(hps['batch_size'],drop_remainder=True)\n",
    "\n",
    "# get numpy version for testing purposes\n",
    "X_test_np = np.stack(list(X_test))\n",
    "X_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = tf.data.Dataset.load('datasets/intcoords/validate').batch(hps['batch_size'],drop_remainder=True)\n",
    "X_val_np = np.stack(list(X_val))\n",
    "X_val_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99987b9b-f1af-4d0f-9205-681bdf2f835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best HP from latest tuning \n",
    "# e.g: \"analysis/xxx-yyy/\"\n",
    "# ... or don't specify, by default use the last analysis\n",
    "\n",
    "analyzer = TuningAnalyzer()\n",
    "analyzer.get_best_hp(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b43a90-fb4f-4554-b2f5-89ce712b0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select HP to use by specifying trial_id\n",
    "#  e.g: trial_id = '483883b929b3445bff6dee9759c4d50ee3a4ba7f0db22e665c49b5f942d9693b'\n",
    "# ... or don't specify, by default use the trial with the lowest score\n",
    "trial_id = ''\n",
    "\n",
    "hps = None\n",
    "for trial in analyzer.sorted_trials:\n",
    "    if trial['trial_id'] == trial_id:\n",
    "        hps = trial['hp']\n",
    "    \n",
    "if not hps:\n",
    "    print(f'Could not find trial with specified ID, using one with the lowest score - {analyzer.sorted_trials[0][\"trial_id\"]}')\n",
    "    hps = analyzer.sorted_trials[0]['hp']\n",
    "    \n",
    "print(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d90fa-8d26-4e85-b45a-9be995273e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best number of encoder and discriminator seeds from plots in tune.ipynb \n",
    "best_enc_seed=128\n",
    "best_disc_seed=32 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Distribution prior\n",
    "Train with common prior distributions. See https://www.tensorflow.org/probability/api_docs/python/tfp/distributions for all available distributions. It is ideal to use tuned Hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the prior p(z)\n",
    "\n",
    "#prior = tfp.distributions.Normal(loc=0, scale=1)\n",
    "#prior = tfp.distributions.Uniform()\n",
    "\n",
    "# ...or Build your custom prior\n",
    "'''\n",
    "tfd = tfp.distributions\n",
    "means = tf.constant([[0.7, 0.0],[-0.7, 0.0],[0.0, 0.7] ], dtype=tf.float32)\n",
    "scales = tf.constant([[0.15, 0.15],[0.15, 0.15],[0.15, 0.15]], dtype=tf.float32)\n",
    "components = tfd.MultivariateNormalDiag(loc=means, scale_diag=scales)\n",
    "mix = tfd.Categorical(probs=[0.3, 0.3, 0.3])\n",
    "\n",
    "prior = tfd.MixtureSameFamily(mixture_distribution=mix, components_distribution=components)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare model using the best hyperparameters from analysis\n",
    "\n",
    "test = asmsa.AAEModel((X_train_np.shape[1],),\n",
    "                       prior=prior,\n",
    "                       hp=hps,\n",
    "                       enc_seed=best_enc_seed,\n",
    "                       disc_seed=best_disc_seed,\n",
    "                       with_density=False\n",
    "                      )\n",
    "test.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train it (can be repeated several times to add more epochs)\n",
    "\n",
    "metric_groups = {\n",
    "    'Autoencoder Loss': ['AE loss min', 'val_val_AE loss min'],\n",
    "    'Discriminator Loss': ['disc loss min', 'val_val_disc loss min']\n",
    "}\n",
    "\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_val_AE loss min\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "test.fit(X_train_batched, \n",
    "          epochs=1000,\n",
    "          verbose=2, \n",
    "          validation_data=X_val,\n",
    "          callbacks=[\n",
    "              early_stop_cb,\n",
    "              LiveTrainingPlot(metric_groups=metric_groups, freq=1),\n",
    "              #visualizer.VisualizeCallback(test,freq=10,inputs=X_train_np[15000:25000],figsize=(12,3)) \n",
    "          ])\n",
    "\n",
    "#Turn on the visualizer if you would like to see the latent space evolution every \"freq\" epochs. We advice to turn off the LiveTrainingPlot to avoid crowded output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final visualization, pick a slice of the input data for demo purposes\n",
    "#visualizer.Visualizer(figsize=(12,3)).make_visualization(testm.call_enc(X_train_np[15000:20000]).numpy())\n",
    "# on test data\n",
    "visualizer.Visualizer(figsize=(12,3)).make_visualization(test.call_enc(X_test_np).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing trajectory for further visualizations and computations\n",
    "tr = md.load('x_train.xtc',top=conf)\n",
    "idx=tr[0].top.select(\"name CA\")\n",
    "\n",
    "# for trivial cases like AlanineDipeptide\n",
    "#idx=tr[0].top.select(\"element != H\") \n",
    "\n",
    "tr.superpose(tr[0],atom_indices=idx)\n",
    "geom = np.moveaxis(tr.xyz ,0,-1)\n",
    "geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rgyr and rmsd color coded in low dim (rough view), compute any other properties according to your needs\n",
    "\n",
    "lows = test.call_enc(X_train_np).numpy()\n",
    "rg = md.compute_rg(tr)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Image prior\n",
    "\n",
    "Use Image as a prior distribution. Again use tuned Hyperparameters for better training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1I2WP92MMWS5s5vin_4cvmruuV-1W77Hl\", \"mushroom_bw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmush = asmsa.AAEModel((X_train_np.shape[1],),\n",
    "                       hp=hps,\n",
    "                       enc_seed=best_enc_seed,\n",
    "                       disc_seed=best_disc_seed,\n",
    "                       prior='mushroom_bw.png'\n",
    "                      )\n",
    "mmush.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_val_AE loss min\",\n",
    "    min_delta=0.0001,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmush.fit(X_train_batched, # X_train_dens, # X_train_batched,\n",
    "          epochs=1000,\n",
    "          verbose=2, \n",
    "          validation_data=X_val,\n",
    "          callbacks=[\n",
    "              early_stop_cb,\n",
    "              LiveTrainingPlot(metric_groups=metric_groups, freq=1),\n",
    "              #visualizer.VisualizeCallback(testm,freq=25,inputs=X_train_np[15000:25000],figsize=(12,3))\n",
    "          ])\n",
    "#Turn on the visualizer if you would like to see the latent space evolution every \"freq\" epochs. We advice to turn off the LiveTrainingPlot to avoid crowded output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rgyr and rmsd color coded in low dim (rough view), compute any other properties according to your needs\n",
    "\n",
    "step=4\n",
    "tr2 = tr[::step]\n",
    "lows = mmush.call_enc(X_test_np[::step]).numpy()\n",
    "rg = md.compute_rg(tr2)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr2,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save the encoder and decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx2torch\n",
    "import tempfile\n",
    "\n",
    "def _convert_to_onnx(model, destination_path):\n",
    "    input_tensor = model.layers[0]._input_tensor\n",
    "    input_signature = tf.TensorSpec(\n",
    "        name=input_tensor.name, shape=input_tensor.shape, dtype=input_tensor.dtype\n",
    "    )\n",
    "    output_name = model.layers[-1].name\n",
    "\n",
    "    @tf.function(input_signature=[input_signature])\n",
    "    def _wrapped_model(input_data):\n",
    "        return {output_name: model(input_data)}\n",
    "\n",
    "    tf2onnx.convert.from_function(\n",
    "        _wrapped_model, input_signature=[input_signature], output_path=destination_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as onnx:\n",
    "    _convert_to_onnx(model.enc,onnx.name)\n",
    "    torch_enc = onnx2torch.convert(onnx.name)\n",
    "\n",
    "example_input = torch.randn([X_train_np.shape[1]])\n",
    "traced_script_module = torch.jit.trace(torch_enc, example_input)\n",
    "\n",
    "traced_script_module.save('encoder-unif.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = torch.jit.load('encoder-unif.pt')\n",
    "example_input = np.random.rand(10000,X_train_np.shape[1])\n",
    "rtf = model.enc(example_input)\n",
    "rpt = lenc(torch.tensor(example_input,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxerr = np.max(np.abs(rtf - rpt.detach().numpy()))\n",
    "maxerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as onnx:\n",
    "    _convert_to_onnx(model.dec,onnx.name)\n",
    "    torch_dec = onnx2torch.convert(onnx.name)\n",
    "\n",
    "example_input = torch.randn([2])\n",
    "traced_script_module = torch.jit.trace(torch_dec, example_input)\n",
    "\n",
    "traced_script_module.save('decoder-unif.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldec = torch.jit.load('decoder-unif.pt')\n",
    "example_input = np.random.rand(10000,2)\n",
    "rtf = model.dec(example_input)\n",
    "rpt = ldec(torch.tensor(example_input,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.abs(rtf - rpt.detach().numpy())\n",
    "train_mean = np.loadtxt('datasets/intcoords/mean.txt',dtype=np.float32).reshape(1,1,-1)\n",
    "rerr = err/np.abs(train_mean)\n",
    "np.max(err),np.max(rerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Final visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_geom = np.moveaxis(np.stack(list(tf.data.Dataset.load('datasets/geoms/test'))),2,0)\n",
    "test_geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = md.load(traj, top=conf)\n",
    "tr.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.loadtxt('datasets/intcoords/mean.txt',dtype=np.float32)\n",
    "train_scale = np.loadtxt('datasets/intcoords/scale.txt',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831cfac-0a28-4ab9-96f4-7897efd5c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = torch.jit.load('features.pt')\n",
    "torch_encoder = torch.jit.load('encoder-unif.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteModel(torch.nn.Module):\n",
    "    def __init__(self, mol_model, torch_encoder, train_mean, train_scale):\n",
    "        super(CompleteModel, self).__init__()\n",
    "        self.mol_model = mol_model\n",
    "        self.torch_encoder = torch_encoder\n",
    "        self.train_mean = torch.from_numpy(np.reshape(train_mean, (-1, 1)))\n",
    "        self.train_scale = torch.from_numpy(np.reshape(train_scale, (-1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mol_output = self.mol_model(x.moveaxis(0,-1))\n",
    "        normalized = (mol_output - self.train_mean) / self.train_scale\n",
    "        return self.torch_encoder(normalized.T)\n",
    "\n",
    "complete_model = CompleteModel(mol_model, torch_encoder, train_mean, train_scale)\n",
    "\n",
    "example_input = torch.randn([1,test_geom.shape[1], test_geom.shape[2]])\n",
    "traced_script_module = torch.jit.trace(complete_model, example_input)\n",
    "\n",
    "model_file_name = \"model.pt\"\n",
    "traced_script_module.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.jit.load('model.pt')\n",
    "lows = m(torch.tensor(tr.xyz)).numpy()\n",
    "np.savetxt(\"lows.txt\", lows)\n",
    "lows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "lows = np.loadtxt(\"lows.txt\")\n",
    "rg = md.compute_rg(tr)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=pot[:,1],cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"??\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.savefig(\"xxx.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bb551-a7a4-42e3-9b23-baaa1d125e96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Other Properties\n",
    "* Color the latent space above with the variables calculated in this section to explore the computed properties in the low dimentinal space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef36a01-a525-47e1-b90e-78848ac08dea",
   "metadata": {},
   "source": [
    "#### Alpha elics\n",
    "* **Traj** must be the tranining .xtc and .pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = md.load_xtc(\"xxx.xtc\", top=\"xxx.pdb\")\n",
    "\n",
    "dssp = md.compute_dssp(traj, simplified=True) \n",
    "alpha_content_per_frame = np.mean(dssp == 'H', axis=1)\n",
    "average_alpha_helix_content = np.mean(alpha_content_per_frame)\n",
    "\n",
    "print(f\"Avarage alpha elics content: {average_alpha_helix_content:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5642a94-98cc-4fe7-bfca-f9d4a1684a1f",
   "metadata": {},
   "source": [
    "#### Contact pairs\n",
    "* **x**: residue number.\n",
    "* **y**:  Ca, Cb or whatever belonging with X, the user wish to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53e5d9-0732-4f03-8054-1e3e0c300855",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_indices = (traj.topology.select(\"resid x and name y\")[0],  \n",
    "                traj.topology.select(\"resid x and name y\")[0])\n",
    "\n",
    "distances = md.compute_distances(traj, [atom_indices])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad99be8-57fd-4db0-a246-194af39abeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'pair: {pairs[94]} \\\n",
    "distance: {distances[:, 94]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48834d9d-80a9-4a8b-96ad-caf54c8edba5",
   "metadata": {},
   "source": [
    "#### Angles\n",
    "* **x**: same as above.\n",
    "* **y**:  same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a57ca1-6fe6-4f29-8802-8df371e9aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_indices = traj.topology.select(\"resid x and name y\")[0], \\\n",
    "               traj.topology.select(\"resid x and name y\")[0], \\\n",
    "               traj.topology.select(\"resid x and name y\")[0]\n",
    "\n",
    "# Radiants\n",
    "angles = md.compute_angles(traj, [atom_indices])  \n",
    "\n",
    "# Degree\n",
    "angles_deg = np.rad2deg(angles[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1906d9fa-08f1-4af6-9e7f-c4945afae145",
   "metadata": {},
   "source": [
    "#### dihedrals\n",
    "* **x**: same as above.\n",
    "* **y**:  same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddfe8f-20a7-4cec-81ce-916c2c45df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom1 = traj.topology.select(\"resid x and name y\")[0]\n",
    "atom2 = traj.topology.select(\"resid x and name y\")[0]\n",
    "atom3 = traj.topology.select(\"resid x and name y\")[0]\n",
    "atom4 = traj.topology.select(\"resid x and name y\")[0]\n",
    "\n",
    "# Radiants\n",
    "dihedrals = md.compute_dihedrals(traj, [[atom1, atom2, atom3, atom4]])\n",
    "# Degree\n",
    "dihedrals_deg = np.rad2deg(dihedrals[:, 0])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
