{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ASMSA: Prepare and check input files\n",
    "\n",
    "**Next steps**\n",
    "- [tune.ipynb](tune.ipynb): Perform initial hyperparameter tuning for this molecule\n",
    "- [train.ipynb](train.ipynb): Use results of previous tuning in more thorough training\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid TF to consume GPU memory\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "tf.config.list_logical_devices()\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import asmsa\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import gromacs as gmx\n",
    "import gromacs.fileformats as gf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input files\n",
    "base = '../DE-Shaw/trpcage_correct'\n",
    "\n",
    "# input conformation, it should not contain hydrogens\n",
    "conf = base + '.pdb'\n",
    "\n",
    "# input trajectory\n",
    "# atom numbering must be consistent with {conf}, no hydrogens as well\n",
    "\n",
    "traj = '../DE-Shaw/trpcage_red.xtc'\n",
    "\n",
    "# everything else is generated with pdb2gmx to make sure the files are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Generate important files\n",
    "\n",
    "   * **Density of additional internal coordinates**: how many randomly sampled distances from all atom-to-atom one atom should appear in average\n",
    "   * **Inputs file generation**: file to be used in the next notebooks\n",
    "   * **pdb2gmx**: convert a PDB file into a GROMACS topology and generate a coordinate file, topology file and index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_density = 2 # integer in [1, n_atoms-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topol = base + '.top'\n",
    "index = base + '.ndx'\n",
    "gro = base + '.gro'\n",
    "\n",
    "with open('inputs.py','w') as i:\n",
    "    i.write(f'''\n",
    "base = '{base}'\n",
    "conf = '{conf}'\n",
    "traj = '{traj}'\n",
    "topol = '{topol}'\n",
    "index = '{index}'\n",
    "gro = '{gro}'\n",
    "\n",
    "nb_density = {nb_density}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.pdb2gmx(f=conf, ignh=True,p=topol,n=index,o=gro,water='tip3p',ff='amber99sb-ildn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Sanity checks:\n",
    " * **Check**: if everything in your trajectory is fine, before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trajectory, it should report expected numbers of frames and atoms/residua\n",
    "\n",
    "tr = md.load(traj,top=conf)\n",
    "idx=tr[0].top.select(\"name CA\")\n",
    "\n",
    "# for trivial cases like Ala-Ala, where superposing on CAs fails\n",
    "#idx=tr[0].top.select(\"element != H\")\n",
    "\n",
    "tr.superpose(tr[0],atom_indices=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check, all frames should look \"reasonable\"\n",
    "\n",
    "# Because of different conventions of numbering atoms in proteins,\n",
    "# PDB file {conf} and the trajectory {traj} can become inconsistent, and this would appear here \n",
    "# as rather weird shapes of the molecule\n",
    "\n",
    "import nglview as nv\n",
    "\n",
    "v = nv.show_mdtraj(tr)\n",
    "v.clear()\n",
    "v.add_representation(\"licorice\")\n",
    "v.add_representation(\"cartoon\")\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Datasets preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a736d3-a2c8-4f12-938f-dcdbb42c750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_orig = tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3eff7-cd68-4f67-ae00-0813b5d4040e",
   "metadata": {},
   "source": [
    "### Shuffle configurations in trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the trajectory so the configurations are dispersed across all datasets\n",
    "np.random.shuffle(tr.xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b33176-8375-4b51-bd2f-8a1cdcf963fe",
   "metadata": {},
   "source": [
    "### Select proportions to divide the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set proportions for train, validation and test datasets\n",
    "# - proportions must be equal to 1 when added together\n",
    "train = .7\n",
    "validation = .15\n",
    "test = .15\n",
    "\n",
    "assert train + validation + test == .9999999999999999 or 1\n",
    "\n",
    "tr_i = len(tr) * train\n",
    "X_train = tr.slice(slice(0,int(tr_i)))\n",
    "\n",
    "va_i = len(tr) * validation\n",
    "X_validate = tr.slice(slice(int(tr_i),int(tr_i)+int(va_i)))\n",
    "\n",
    "te_i = len(tr) * test\n",
    "X_test = tr.slice(slice(int(tr_i)+int(va_i),len(tr)))\n",
    "\n",
    "X_train.xyz.shape, X_validate.xyz.shape, X_test.xyz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d4e072-04ab-45b7-a427-62758fd566ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Divide the trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.save_xtc('train.xtc')\n",
    "X_validate.save_xtc('validate.xtc')\n",
    "X_test.save_xtc('test.xtc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventual recovery\n",
    "\n",
    "X_train = md.load_xtc('train.xtc',conf)\n",
    "X_validate = md.load_xtc('validate.xtc',conf)\n",
    "X_test = md.load_xtc('test.xtc',conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Compute RMSD between\n",
    "   * **train x validation** trajectory and filter similar structures in train trajectory\n",
    "   * **train x test** trajectory and filter similar structures in train trajectory\n",
    "   * **test x validation** trajectory and filter similar structures in test trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSD from train trajectory compared to validation trajectory\n",
    "gmx.select(s=conf,on='backbone.ndx',select='Backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.rms(s=conf,f='train.xtc',f2='validate.xtc',n='backbone.ndx',m='trainxval_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RMDS matrix\n",
    "txv = gf.XPM('trainxval_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minima per row -- for each configuration in train, how far is the nearest one from validation\n",
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop similar structures (to validation trajectory) in train trajectory to avoid dataset being biased\n",
    "txv_difference = 0.05\n",
    "\n",
    "train_tr = X_train[np.argwhere(txv_min > txv_difference).flat]\n",
    "train_tr.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr.save_xtc('tmp_train.xtc')\n",
    "gmx.rms(s=conf,f='tmp_train.xtc',f2='test.xtc',n='backbone.ndx',m='trainxtest_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = gf.XPM('trainxtest_rmsd.xpm')\n",
    "txt.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_min = np.min(txt.array,axis=1)\n",
    "txt_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txt_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txt_difference = 0.05\n",
    "\n",
    "x_train = train_tr[np.argwhere(txt_min > txt_difference).flat]\n",
    "x_train.save_xtc('x_train.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test x validation\n",
    "gmx.rms(f='test.xtc',f2='validate.xtc',s=conf,n='backbone.ndx',m='testxvalidate_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv = gf.XPM('testxvalidate_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txv_difference = 0.05\n",
    "\n",
    "x_test = X_test[np.argwhere(txv_min > txv_difference).flat]\n",
    "x_test.save_xtc('x_test.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# skip thorough RMS\n",
    "! ln train.xtc x_train.xtc\n",
    "! ln test.xtc x_test.xtc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovery\n",
    "\n",
    "x_train = md.load('../DE-Shaw/x_train.xtc', top=conf)\n",
    "x_test = md.load('../DE-Shaw/x_test.xtc', top=conf)\n",
    "x_all = md.load('../DE-Shaw/trpcage_red.xtc', top=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### Save computetd geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shapes of filtered trajectories that are to be used as datasets\n",
    "validate_tr = md.load('../DE-Shaw/validate.xtc', top=conf)\n",
    "\n",
    "trajs = [x_train, validate_tr, x_test, x_all]\n",
    "x_train.xyz.shape, validate_tr.xyz.shape, x_test.xyz.shape, x_all.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle the geometries to get frame last so that we can use vectorized calculations later on\n",
    "geoms = [ np.moveaxis(t.xyz,0,-1) for t in trajs]\n",
    "print ([ g.shape for g in geoms ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save geometries\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(geoms[0]).save('datasets/geoms/train')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[1]).save('datasets/geoms/validate')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[2]).save('datasets/geoms/test')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[3]).save('dataset/geoms/X_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Internal coordinates computation\n",
    "\n",
    "Exercise the ASMSA library on your input. Just check everything appears to work.\n",
    "\n",
    "There are multiple options that can be combined:\n",
    "* use traditional internal coordinates (bond distances, angles, and dihedrals) or not\n",
    "* include additional distances between atoms that may not be bound to express protein folding state more directly\n",
    "   * dense (all-to-all) atom distances, feasible for very small peptides only\n",
    "   * sparse atom distances (only some pairs are chosen)\n",
    "   \n",
    "* We save the computed internal coordinates for training, and a feature extraction model here, therefore everything in the other notebooks should work too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "#### Compute atom indexes : \n",
    "* Backbone\n",
    "* ON (bacbone Oxigens, Nitrogens)\n",
    "* Polar atoms\n",
    "* Alpha Carbons\n",
    "* Alpha-Beta Carbons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27c253-9e29-45c5-9ccd-8b5aa3f1bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_path = conf\n",
    "\n",
    "backbone = []\n",
    "with open(pdb_path) as f:\n",
    "    atom_counter = 0\n",
    "    for line in f:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        name = line[12:16].strip()\n",
    "        if name == \"N\" or name == \"C\" or name==\"CA\":\n",
    "            backbone.append(atom_counter)\n",
    "        atom_counter += 1\n",
    "\n",
    "ON = []\n",
    "with open(pdb_path) as f:\n",
    "    atom_counter = 0\n",
    "    for line in f:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        name = line[12:16].strip()\n",
    "        if name == \"N\" or name == \"O\":\n",
    "            ON.append(atom_counter)\n",
    "        atom_counter += 1\n",
    "\n",
    "polar = []\n",
    "with open(pdb_path) as f:\n",
    "    atom_counter = 0\n",
    "    for line in f:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        name = line[12:16].strip()\n",
    "        pol = {\n",
    "            \"N\", #backbone amide nitrogen\n",
    "            \"O\", #backbone carbonyl oxygen\n",
    "            \"OG\", #Serine\n",
    "            \"OG1\", #Threonine\n",
    "            \"OH2\", #Tyrosine\n",
    "            \"SG\", #Cysteine\n",
    "            \"OD1\", #Aspartate\n",
    "            \"OD2\", #Aspartate\n",
    "            \"OE1\", #Glutamate\n",
    "            \"OE2\", #Glutamate \n",
    "            \"ND2\", #Asparagine\n",
    "            \"OD1\", #Asparagine\n",
    "            \"NE2\", #Glutamine\n",
    "            \"OE1\", #Glutamine\n",
    "            \"ND1\", #Histidine\n",
    "            \"NE2\", #Histidine\n",
    "            \"NZ\", #Lysine\n",
    "            \"NE\", #Arginine\n",
    "            \"NH1\", #Arginine\n",
    "            \"NH2\", #Arginine\n",
    "        }\n",
    "        if name in pol:\n",
    "            polar.append(atom_counter)\n",
    "        atom_counter += 1\n",
    "\n",
    "            \n",
    "alpha = []\n",
    "with open(pdb_path) as f:\n",
    "    atom_counter = 0\n",
    "    for line in f:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        name = line[12:16].strip()\n",
    "        if name == \"CA\":\n",
    "            alpha.append(atom_counter)\n",
    "        atom_counter += 1\n",
    "\n",
    "alphabeta = []\n",
    "with open(pdb_path) as f:\n",
    "    atom_counter = 0\n",
    "    for line in f:\n",
    "        if not line.startswith(\"ATOM\"):\n",
    "            continue\n",
    "        name = line[12:16].strip()\n",
    "        if name == \"CA\" or name == \"CB\":\n",
    "            alphabeta.append(atom_counter)\n",
    "        atom_counter += 1\n",
    "\n",
    "print(f'Backbone({len(backbone)}): {backbone}')\n",
    "print(f'ON({len(ON)}): {ON}')\n",
    "print(f'Polar Atoms ({len(polar)}): {polar}')\n",
    "print(f'Alpha C ({len(alpha)}): {alpha}')\n",
    "print(f'Alpha and Beta ({len(alphabeta)}): {alphabeta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1c31b5-8179-407e-bd52-c17e2ca40039",
   "metadata": {},
   "source": [
    "#### Extract:\n",
    "* Bonds\n",
    "* Angles\n",
    "* Dihedrals\n",
    "* Dihedrlas: phi-psi only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710fa9b-6abe-403a-8a66-f401f70720be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bonds = np.array([[backbone[i], backbone[i+1]] for i in range(len(backbone) - 1)])\n",
    "angles = np.array([[backbone[i], backbone[i+1], backbone[i+2]] for i in range(len(backbone) - 2)])\n",
    "dih = np.array([backbone[i:i+4] for i in range(len(backbone) - 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f15d4-a4b1-4ed6-9fd8-351dd2f70045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!!! TO BE CHECKED \n",
    "\n",
    "mask = np.ones(len(dih), dtype=bool)\n",
    "\n",
    "mask[1] = False\n",
    "\n",
    "for i in range(2, len(mask)):\n",
    "    mask[i] = ((i-2) % 3) != 2\n",
    "phipsi = dih[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149397b-aa28-41f4-95e2-a89236821183",
   "metadata": {},
   "source": [
    "#### Compute distances:\n",
    "* 1) **Choose** the atom selection (e.g atoms = ON): the atoms will be considered for the random pick with the density selection.\n",
    "  2) **If** \"sparse\" choose the density.\n",
    "  3) **If** \"dense\" all the atoms will be considered.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=5,  atoms = ON)\n",
    "dense_dists = asmsa.NBDistancesDense(geoms[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b0c52-3d80-41dc-adcd-eb8447781577",
   "metadata": {},
   "source": [
    "#### Biuld:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b6fa7-f6a5-47a8-a469-140861e09b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mol=asmsa.Molecule(pdb=conf,top=topol,fms=[dense_dists])\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   diheds=phipsi,\n",
    "                   fms=[sparse_dists]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50bcb8-a1da-46b2-bee6-72515e5d44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sparse_dists.bonds)\n",
    "#len(dense_dists.bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol.describe_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "#### Save the features (molecule) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))\n",
    "traced_script_module = torch.jit.trace(mol_model, example_input)\n",
    "\n",
    "traced_script_module.save('features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "#### Compute the interanal coordinates now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "intcoords = [ mol.intcoord(g).T for g in geoms]\n",
    "print(\n",
    "    [ g.shape for g in geoms ],\n",
    "    [ i.shape for i in intcoords ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train,validate,test, X_all] = intcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = mol_model.dihed4_model(torch.from_numpy(geoms[2])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, geoms):\n",
    "#        geoms = input.reshape(self.n_atoms, 3, -1)\n",
    "    a12 = geoms[self.atoms[:, 1]] - geoms[self.atoms[:, 0]]\n",
    "    a23 = geoms[self.atoms[:, 2]] - geoms[self.atoms[:, 1]]\n",
    "    a34 = geoms[self.atoms[:, 3]] - geoms[self.atoms[:, 2]]\n",
    "\n",
    "#        a12 = torch.nn.functional.normalize(a12, p=2, dim=1)\n",
    "#        a23 = torch.nn.functional.normalize(a23, p=2, dim=1)\n",
    "#        a34 = torch.nn.functional.normalize(a34, p=2, dim=1)\n",
    "\n",
    "    vp1 = torch.nn.functional.normalize(torch.cross(a12,a23,axis=1))\n",
    "    vp2 = torch.nn.functional.normalize(torch.cross(a23,a34,axis=1))\n",
    "    vp3 = torch.nn.functional.normalize(torch.cross(vp1,a23,axis=1))\n",
    "\n",
    "    sp1 = torch.sum(vp1 * vp2, axis=1)\n",
    "    sp2 = torch.sum(vp3 * vp2, axis=1)\n",
    "\n",
    "    \"\"\" original:\n",
    "    # output for i-th dihedral angle\n",
    "        aa = np.arctan2(sp1,sp2) - np.pi * .5\n",
    "        return np.sin(aa), np.cos(aa)\n",
    "    \"\"\"\n",
    "\n",
    "    #NOTE: Why adding two variables that determine each other? It the angle better?\n",
    "    # return torch.nn.functional.normalize(torch.stack([-sp2, sp1]), p=2, dim=0).reshape(2*len(self.atoms), geoms.shape[2])\n",
    "    return sp1,sp2\n",
    "    #return torch.stack([-sp2, sp1]).reshape(2*len(self.atoms), geoms.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1,sp2 = forward(mol_model.dihed4_model,torch.from_numpy(geoms[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.shape,sp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([-sp2, sp1]).reshape((146,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.from_numpy(np.array([[1,2,3],[4,5,6]]))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = a1+.2\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([a1,a2]).reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the saved model -- should yield nearly 0.\n",
    "\n",
    "test_from_model = mol_model(torch.from_numpy(geoms[2])).numpy()\n",
    "np.max(test - test_from_model.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_from_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training set\n",
    "train_mean = np.mean(train,axis=0)\n",
    "train -= train_mean\n",
    "train_scale = np.std(train,axis=0)\n",
    "train /= train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test and validation sets\n",
    "test -= train_mean\n",
    "test /= train_scale\n",
    "validate -= train_mean\n",
    "validate /= train_scale\n",
    "X_all -= train_mean\n",
    "X_all /= train_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "#### Save the features (molecule) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))\n",
    "traced_script_module = torch.jit.trace(mol_model, example_input)\n",
    "\n",
    "traced_script_module.save('features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "#### Save internal coordinates as datasets which can be loaded in **train.ipynb** and **tune.ipynb** notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for usage in tune/train/test phase\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(train).save('datasets/intcoords/train')\n",
    "tf.data.Dataset.from_tensor_slices(validate).save('datasets/intcoords/validate')\n",
    "tf.data.Dataset.from_tensor_slices(test).save('datasets/intcoords/test')\n",
    "tf.data.Dataset.from_tensor_slices(X_all).save('datasets/intcoords/X_all')\n",
    "\n",
    "np.savetxt('datasets/intcoords/mean.txt',train_mean)\n",
    "np.savetxt('datasets/intcoords/scale.txt',train_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Density of the conformational space\n",
    "\n",
    "- Sample the training trajectory randomly\n",
    "- For each point in the trajectory:\n",
    "  - calculate RMSD to all points in the sample\n",
    "  - pick some number $n$ of nearest ones\n",
    "  - calculate the _density_ at this point as $$ d = \\sum_{i=1}^n e^{-d_i} / n $$  i.e. the nearer the sample points are, the higher the density\n",
    " \n",
    "Altogether, $d$ roughly corresponds to the probability that the molecule during simulation ends up in this area of the conformational space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "x_train = md.load('x_train.xtc', top=conf)\n",
    "tr_sample = x_train[np.random.choice(len(x_train),sample_size,False)]\n",
    "tr_sample.save('sample.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.rms(f='x_train.xtc',f2='sample.xtc',s=conf,n='backbone.ndx',m='sample_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = gf.XPM('sample_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### Visual check to verify the sample size is representative\n",
    "- typically, not many distances should be less than 0.1 nm and more than 1 nm \n",
    "(the latter depends on the molecule, can be more for e.g. big disordered proteins)\n",
    "- the histogram should be semi-smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rms.array.flatten(),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest = 200\n",
    "rms_sort = np.sort(rms.array.astype(np.float32))\n",
    "erms = np.exp(-rms_sort[:,:k_nearest])\n",
    "dens = (np.sum(erms,axis=1)-1.) / (erms.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "#### Histogram of densities\n",
    "- quite high number of points should fall above 0.8, those are low energy basins\n",
    "- the interval [0.5, 1.0] should be reasonably covered\n",
    "- on the contrary, too many points below 0.4 would indicate either insufficient sampling above or too sparse trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dens,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dens),len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('datasets/train_density.txt',dens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
