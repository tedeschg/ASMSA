{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7a3cf0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457ea1f",
   "metadata": {},
   "source": [
    "## Featurizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b2509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 14:14:28.539911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-31 14:14:28.554980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-31 14:14:28.561592: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-31 14:14:28.573534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-31 14:14:29.510841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a629a7eae2d841e49070bbaef3f892c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import nglview as nv\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "from utils import split_dataset\n",
    "from vae import build_asmsa_vae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172d539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdtraj.Trajectory with 50001 frames, 144 atoms, 20 residues, and unitcells at 0x7f9f7ef86cb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = \"trpcage_ds_nH.xtc\"\n",
    "conf = \"trpcage_npt400_nH.pdb\"\n",
    "\n",
    "traj = md.load_xtc(tr, top=conf)\n",
    "backbone_atoms = traj.topology.select('backbone')\n",
    "traj.superpose(traj, 0, atom_indices=backbone_atoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980dcc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad3d4ce110e43eba5550b24b8c03a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=50000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = nv.show_mdtraj(traj)\n",
    "\n",
    "view.add_representation('line', selection='protein')\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ba69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames, n_atoms = traj.n_frames, traj.n_atoms #50001, 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb9bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_indices = traj.topology.select(\"protein\")\n",
    "n_p = len(p_indices)\n",
    "\n",
    "bb_indices = traj.topology.select(\"backbone\")\n",
    "n_bb = len(bb_indices)\n",
    "\n",
    "ca_indices = traj.topology.select(\"name CA\")\n",
    "pairs = np.array([(i, j) for idx,i in enumerate(ca_indices) \n",
    "                          for j in ca_indices[idx+1:]])\n",
    "\n",
    "coords_bb = traj.xyz[:,bb_indices,:]\n",
    "#coords = traj.xyz.reshape(n_frames, n_atoms * 3) #from (n_frame, n_atoms, 3) to (n_frame, n_atoms*3) \n",
    "coords = coords_bb.reshape(n_frames, -1)\n",
    "\n",
    "dists = md.compute_distances(traj, pairs) \n",
    "\n",
    "bonds = list(traj.topology.bonds)\n",
    "bond_pairs = [[b.atom1.index, b.atom2.index] for b in bonds]\n",
    "bond_lengths = md.compute_distances(traj, bond_pairs)\n",
    "\n",
    "\n",
    "phi_angles = md.compute_phi(traj)[1]\n",
    "psi_angles = md.compute_psi(traj)[1]\n",
    "phi_sin = np.sin(phi_angles)\n",
    "phi_cos = np.cos(phi_angles)  \n",
    "psi_sin = np.sin(psi_angles)\n",
    "psi_cos = np.cos(psi_angles)\n",
    "\n",
    "# Side chain dihedrals with sin/cos\n",
    "chi1_angles = md.compute_chi1(traj)[1]\n",
    "chi2_angles = md.compute_chi2(traj)[1]\n",
    "chi1_sin = np.sin(chi1_angles)\n",
    "chi1_cos = np.cos(chi1_angles)\n",
    "chi2_sin = np.sin(chi2_angles) \n",
    "chi2_cos = np.cos(chi2_angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20e6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.concatenate([coords,phi_sin,phi_cos,psi_sin,psi_cos,chi1_sin,chi1_cos,chi2_sin,chi2_cos], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a207f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 366)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features_normalized = scaler.fit_transform(feat)\n",
    "features_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7a498",
   "metadata": {},
   "source": [
    "## NN preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013f3c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 14:14:35.302452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8075 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:61:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "  Train: 35000 samples, 546 batches\n",
      "  Val:   7500 samples, 118 batches\n",
      "  Test:  7501 samples, 118 batches\n",
      "  Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "# Uso:\n",
    "ds_train, ds_val, ds_test, ds_all = split_dataset(features_normalized, train_size=70, val_size=15, batch_size=64, seed=42)\n",
    "\n",
    "# Opzionale: Data Augmentation per autoencoder\n",
    "def add_data_augmentation(ds_train, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore ai dati di input mantenendo il target pulito\n",
    "    \"\"\"\n",
    "    def add_noise(x, y):\n",
    "        noise = tf.random.normal(tf.shape(x), stddev=noise_factor)\n",
    "        x_noisy = x + noise\n",
    "        x_noisy = tf.clip_by_value(x_noisy, 0.0, 1.0)  # Assumendo dati normalizzati [0,1]\n",
    "        return x_noisy, y  # Input rumoroso, target pulito\n",
    "    \n",
    "    return ds_train.map(add_noise, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Per usare data augmentation:\n",
    "# ds_train = add_data_augmentation(ds_train, noise_factor=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1de9f",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49748932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBatch Norm, nel caso, va prima della layer activation)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Batch Norm, nel caso, va prima della layer activation)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b606e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "vae, encoder, decoder = build_asmsa_vae(feat.shape[1], latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec188c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/autoencoder/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,        # salva istogrammi dei pesi ogni epoca\n",
    "    write_graph=True,        # salva anche il grafo del modello\n",
    "    update_freq='epoch',     # ogni epoca\n",
    "    ),\n",
    "\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=15,  # più pazienza con lr scheduling\n",
    "        min_delta=1e-5,  # soglia più stretta\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'best_autoencoder_{latent_dim}d.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528c260",
   "metadata": {},
   "source": [
    "tensorboard --logdir logs/autoencoder --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47361719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753971281.625185   31675 service.cc:146] XLA service 0x7f992801ff20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753971281.625321   31675 service.cc:154]   StreamExecutor device (0): NVIDIA A100 80GB PCIe MIG 1g.10gb, Compute Capability 8.0\n",
      "2025-07-31 14:14:41.753423: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-31 14:14:42.337009: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 12/546\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - kl_loss: 0.9727 - loss: 1.6669 - reconstruction_loss: 0.6942    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753971285.010194   31675 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.1063 - loss: 0.7901 - reconstruction_loss: 0.6838\n",
      "Epoch 1: val_loss improved from inf to 0.66318, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - kl_loss: 0.1055 - loss: 0.7891 - reconstruction_loss: 0.6837 - val_kl_loss: 0.0039 - val_loss: 0.6632 - val_reconstruction_loss: 0.6593 - learning_rate: 1.0000e-04\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.6619 - reconstruction_loss: 0.6592\n",
      "Epoch 2: val_loss improved from 0.66318 to 0.65955, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.6619 - reconstruction_loss: 0.6592 - val_kl_loss: 0.0010 - val_loss: 0.6595 - val_reconstruction_loss: 0.6585 - learning_rate: 1.0000e-04\n",
      "Epoch 3/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 8.1530e-04 - loss: 0.6594 - reconstruction_loss: 0.6586\n",
      "Epoch 3: val_loss improved from 0.65955 to 0.65860, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 8.1499e-04 - loss: 0.6594 - reconstruction_loss: 0.6586 - val_kl_loss: 3.9356e-04 - val_loss: 0.6586 - val_reconstruction_loss: 0.6582 - learning_rate: 1.0000e-04\n",
      "Epoch 4/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 3.2144e-04 - loss: 0.6585 - reconstruction_loss: 0.6582\n",
      "Epoch 4: val_loss improved from 0.65860 to 0.65821, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - kl_loss: 3.2086e-04 - loss: 0.6585 - reconstruction_loss: 0.6582 - val_kl_loss: 1.8604e-04 - val_loss: 0.6582 - val_reconstruction_loss: 0.6580 - learning_rate: 1.0000e-04\n",
      "Epoch 5/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.6092e-04 - loss: 0.6584 - reconstruction_loss: 0.6582\n",
      "Epoch 5: val_loss improved from 0.65821 to 0.65804, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 1.6064e-04 - loss: 0.6584 - reconstruction_loss: 0.6582 - val_kl_loss: 1.1008e-04 - val_loss: 0.6580 - val_reconstruction_loss: 0.6579 - learning_rate: 1.0000e-04\n",
      "Epoch 6/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 9.8914e-05 - loss: 0.6581 - reconstruction_loss: 0.6580\n",
      "Epoch 6: val_loss improved from 0.65804 to 0.65792, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 9.8836e-05 - loss: 0.6581 - reconstruction_loss: 0.6580 - val_kl_loss: 7.6016e-05 - val_loss: 0.6579 - val_reconstruction_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 7/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 6.9763e-05 - loss: 0.6580 - reconstruction_loss: 0.6580\n",
      "Epoch 7: val_loss improved from 0.65792 to 0.65785, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 6.9710e-05 - loss: 0.6580 - reconstruction_loss: 0.6580 - val_kl_loss: 5.6611e-05 - val_loss: 0.6578 - val_reconstruction_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 8/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 5.2909e-05 - loss: 0.6580 - reconstruction_loss: 0.6580\n",
      "Epoch 8: val_loss improved from 0.65785 to 0.65782, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 5.2849e-05 - loss: 0.6580 - reconstruction_loss: 0.6580 - val_kl_loss: 4.4060e-05 - val_loss: 0.6578 - val_reconstruction_loss: 0.6578 - learning_rate: 1.0000e-04\n",
      "Epoch 9/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 4.1142e-05 - loss: 0.6579 - reconstruction_loss: 0.6578\n",
      "Epoch 9: val_loss improved from 0.65782 to 0.65778, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 4.1134e-05 - loss: 0.6579 - reconstruction_loss: 0.6578 - val_kl_loss: 3.5332e-05 - val_loss: 0.6578 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 10/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 3.2493e-05 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 10: val_loss improved from 0.65778 to 0.65775, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 3.2478e-05 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 2.7714e-05 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 11/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 2.5856e-05 - loss: 0.6579 - reconstruction_loss: 0.6578\n",
      "Epoch 11: val_loss improved from 0.65775 to 0.65773, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 2.5837e-05 - loss: 0.6579 - reconstruction_loss: 0.6578 - val_kl_loss: 2.2246e-05 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 2.0458e-05 - loss: 0.6579 - reconstruction_loss: 0.6579\n",
      "Epoch 12: val_loss improved from 0.65773 to 0.65771, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 2.0451e-05 - loss: 0.6579 - reconstruction_loss: 0.6579 - val_kl_loss: 1.7567e-05 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.6212e-05 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 13: val_loss improved from 0.65771 to 0.65770, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 1.6200e-05 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 1.3806e-05 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.2658e-05 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 14: val_loss improved from 0.65770 to 0.65769, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 1.2649e-05 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 1.0989e-05 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 15/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.0009e-05 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 15: val_loss improved from 0.65769 to 0.65767, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 1.0007e-05 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 8.5160e-06 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 16/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 7.8889e-06 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 16: val_loss did not improve from 0.65767\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 7.8822e-06 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 6.7981e-06 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 17/500\n",
      "\u001b[1m536/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 6.1218e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 17: val_loss improved from 0.65767 to 0.65766, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 6.1155e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 5.3036e-06 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 18/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 4.7605e-06 - loss: 0.6576 - reconstruction_loss: 0.6576\n",
      "Epoch 18: val_loss improved from 0.65766 to 0.65766, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 4.7585e-06 - loss: 0.6576 - reconstruction_loss: 0.6576 - val_kl_loss: 4.1813e-06 - val_loss: 0.6577 - val_reconstruction_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 19/500\n",
      "\u001b[1m534/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 3.7762e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 19: val_loss improved from 0.65766 to 0.65764, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 3.7719e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 3.3695e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 1.0000e-04\n",
      "Epoch 20/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 2.9993e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 20: val_loss did not improve from 0.65764\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 2.9988e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 2.8338e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 21/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 2.6323e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 21: val_loss did not improve from 0.65764\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 2.6314e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 2.5317e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 22/500\n",
      "\u001b[1m533/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 2.3381e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 22: val_loss did not improve from 0.65764\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 2.3361e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 2.1777e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 23/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 2.0264e-06 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 23: val_loss improved from 0.65764 to 0.65763, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 2.0259e-06 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 1.9029e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 24/500\n",
      "\u001b[1m534/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 1.7536e-06 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 24: val_loss improved from 0.65763 to 0.65763, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 1.7521e-06 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 1.6248e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 25/500\n",
      "\u001b[1m532/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 1.5126e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 25: val_loss did not improve from 0.65763\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 1.5111e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 1.3936e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 26/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 1.2926e-06 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.65763\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 1.2924e-06 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 1.2031e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 5.0000e-05\n",
      "Epoch 27/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - kl_loss: 1.1080e-06 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 27: val_loss did not improve from 0.65763\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - kl_loss: 1.1078e-06 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 1.0917e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 2.5000e-05\n",
      "Epoch 28/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 1.0341e-06 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 28: val_loss improved from 0.65763 to 0.65762, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 1.0341e-06 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 1.0035e-06 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 2.5000e-05\n",
      "Epoch 29/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 9.5305e-07 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 29: val_loss improved from 0.65762 to 0.65762, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 9.5301e-07 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 9.2742e-07 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 2.5000e-05\n",
      "Epoch 30/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 8.7115e-07 - loss: 0.6578 - reconstruction_loss: 0.6578\n",
      "Epoch 30: val_loss did not improve from 0.65762\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 8.7112e-07 - loss: 0.6578 - reconstruction_loss: 0.6578 - val_kl_loss: 8.6226e-07 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 2.5000e-05\n",
      "Epoch 31/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 8.0373e-07 - loss: 0.6577 - reconstruction_loss: 0.6577\n",
      "Epoch 31: val_loss improved from 0.65762 to 0.65762, saving model to best_autoencoder_64d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 8.0369e-07 - loss: 0.6577 - reconstruction_loss: 0.6577 - val_kl_loss: 7.9934e-07 - val_loss: 0.6576 - val_reconstruction_loss: 0.6576 - learning_rate: 2.5000e-05\n",
      "Epoch 32/500\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-4\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=1e-5, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    "    )\n",
    "\n",
    "vae.compile(optimizer=optimizer)\n",
    "vae.fit(ds_train, epochs=500, validation_data=ds_val, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5dd8a",
   "metadata": {},
   "source": [
    "# Decode and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a36f68-4599-4f52-aca9-b3f5bed65c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model(f'best_autoencoder_2d.keras')\n",
    "encoder = autoencoder.get_layer(\"encoder\")\n",
    "decoder = autoencoder.get_layer(\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73e3af-d99f-4884-bf9d-3887b5a60ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_latent_space(latent_dim, encoder, dataset, conf, target, cmap='rainbow', figsize=(8,8)):\n",
    "    \"\"\"\n",
    "    Computes latent embeddings and plots them in 2D.\n",
    "\n",
    "    Args:\n",
    "        encoder: the encoder model returning [z_mean, z_log_var, z]\n",
    "        dataset: input data or tf.data.Dataset yielding inputs (and optionally labels)\n",
    "        labels: optional array-like of same length as dataset for coloring\n",
    "        cmap: matplotlib colormap\n",
    "        figsize: tuple for figure size\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    results = encoder.predict(dataset)\n",
    "    # results = [z_mean, z_log_var, z]\n",
    "    emb = np.array(results[2])  # results[2] use sampled z; shape (N,2)\n",
    "\n",
    "    rms_ref = md.load_pdb(conf)\n",
    "    rms_ref_bb   = rms_ref.atom_slice(bb_indices)\n",
    "    rms_tr = md.load_xtc(tr, top=rms_ref)\n",
    "    rmsd = md.rmsd(rms_tr, rms_ref)\n",
    "\n",
    "    #z = np.random.normal(loc=0.0, scale=1.0, size=(latent_dim,))\n",
    "\n",
    "    dists = np.linalg.norm(emb - target, axis=1)\n",
    "    # 4a. Se vuoi, ad esempio, le K righe più vicine:\n",
    "    K = 1\n",
    "    idx_closest = np.argsort(dists)[:K]\n",
    "    sample = emb[idx_closest].reshape(1, latent_dim)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.scatter(emb[:,0], emb[:,1], c=rmsd,s=0.5, cmap=cmap)\n",
    "    plt.scatter(sample[:,0], sample[:,1], marker=\"X\", c=\"Black\")\n",
    "\n",
    "    plt.show()\n",
    "    return emb, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2019c-5f03-4026-905a-dc540689abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "target = np.array([0,0]).reshape(1, 2)\n",
    "emb, sample = plot_latent_space(latent_dim, encoder, ds_all, conf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1941133-5a13-4f91-9460-bb803001b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape\n",
    "\n",
    "rms_ref = md.load_pdb(conf)\n",
    "rms_ref_bb   = rms_ref.atom_slice(bb_indices)\n",
    "rms_tr = md.load_xtc(tr, top=rms_ref)\n",
    "rmsd = md.rmsd(rms_tr, rms_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ab5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = decoder.predict(sample)\n",
    "s_orig = scaler.inverse_transform(s)\n",
    "\n",
    "coords_flat = s_orig[0, :coords.shape[1]]                    \n",
    "coords_recons = coords_flat.reshape((n_bb, 3))\n",
    "\n",
    "new_traj = md.Trajectory(\n",
    "    xyz=np.array([coords_recons]),     \n",
    "    topology=rms_ref_bb.topology     \n",
    ")\n",
    "\n",
    "\n",
    "new_traj.save_pdb(\"reconstructed.pdb\")\n",
    "\n",
    "import nglview as nv\n",
    "\n",
    "view = nv.show_file('reconstructed.pdb')\n",
    "view.clear_representations()\n",
    "view.add_line() \n",
    "#view.add_cartoon()\n",
    "view.center()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be6feb-d0a6-4ddf-904b-046708791eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
