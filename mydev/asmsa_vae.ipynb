{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7a3cf0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457ea1f",
   "metadata": {},
   "source": [
    "## Featurizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b2509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 05:18:35.957291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-01 05:18:35.972173: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-01 05:18:35.977034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-01 05:18:35.990323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-01 05:18:36.714577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18b554cc2914671ad8bce981520ae55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ASMSA/mydev\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import nglview as nv\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "%cd /home/jovyan/ASMSA/mydev\n",
    "\n",
    "import os, sys\n",
    "\n",
    "repo_dir = os.getcwd()   \n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.insert(0, repo_dir)\n",
    "\n",
    "# 3. Fai l’import “pulito”\n",
    "from utils import split_dataset\n",
    "from vae import build_asmsa_beta_vae, BetaVAEMonitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172d539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mdtraj.Trajectory with 50001 frames, 144 atoms, 20 residues, and unitcells at 0x77b6acbcece0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = \"trpcage_ds_nH.xtc\"\n",
    "conf = \"trpcage_npt400_nH.pdb\"\n",
    "\n",
    "traj = md.load_xtc(tr, top=conf)\n",
    "backbone_atoms = traj.topology.select('backbone')\n",
    "traj.superpose(traj, 0, atom_indices=backbone_atoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980dcc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9285a3cfeb4704bdf9511cf0c82cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(max_frame=50000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = nv.show_mdtraj(traj)\n",
    "\n",
    "view.add_representation('line', selection='protein')\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ba69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames, n_atoms = traj.n_frames, traj.n_atoms #50001, 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb9bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_indices = traj.topology.select(\"protein\")\n",
    "n_p = len(p_indices)\n",
    "\n",
    "bb_indices = traj.topology.select(\"backbone\")\n",
    "n_bb = len(bb_indices)\n",
    "\n",
    "ca_indices = traj.topology.select(\"name CA\")\n",
    "pairs = np.array([(i, j) for idx,i in enumerate(ca_indices) \n",
    "                          for j in ca_indices[idx+1:]])\n",
    "\n",
    "coords_bb = traj.xyz[:,bb_indices,:]\n",
    "#coords = traj.xyz.reshape(n_frames, n_atoms * 3) #from (n_frame, n_atoms, 3) to (n_frame, n_atoms*3) \n",
    "coords = coords_bb.reshape(n_frames, -1)\n",
    "\n",
    "dists = md.compute_distances(traj, pairs) \n",
    "\n",
    "bonds = list(traj.topology.bonds)\n",
    "bond_pairs = [[b.atom1.index, b.atom2.index] for b in bonds]\n",
    "bond_lengths = md.compute_distances(traj, bond_pairs)\n",
    "\n",
    "\n",
    "phi_angles = md.compute_phi(traj)[1]\n",
    "psi_angles = md.compute_psi(traj)[1]\n",
    "phi_sin = np.sin(phi_angles)\n",
    "phi_cos = np.cos(phi_angles)  \n",
    "psi_sin = np.sin(psi_angles)\n",
    "psi_cos = np.cos(psi_angles)\n",
    "\n",
    "# Side chain dihedrals with sin/cos\n",
    "chi1_angles = md.compute_chi1(traj)[1]\n",
    "chi2_angles = md.compute_chi2(traj)[1]\n",
    "chi1_sin = np.sin(chi1_angles)\n",
    "chi1_cos = np.cos(chi1_angles)\n",
    "chi2_sin = np.sin(chi2_angles) \n",
    "chi2_cos = np.cos(chi2_angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20e6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.concatenate([coords,phi_sin,phi_cos,psi_sin,psi_cos,chi1_sin,chi1_cos,chi2_sin,chi2_cos], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a207f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 366)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features_normalized = scaler.fit_transform(feat)\n",
    "features_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea7a498",
   "metadata": {},
   "source": [
    "## NN preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013f3c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 05:18:42.337424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8075 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:61:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "  Train: 35000 samples, 546 batches\n",
      "  Val:   7500 samples, 118 batches\n",
      "  Test:  7501 samples, 118 batches\n",
      "  Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "# Uso:\n",
    "ds_train, ds_val, ds_test, ds_all = split_dataset(features_normalized, train_size=70, val_size=15, batch_size=64, seed=42)\n",
    "\n",
    "# Opzionale: Data Augmentation per autoencoder\n",
    "def add_data_augmentation(ds_train, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore ai dati di input mantenendo il target pulito\n",
    "    \"\"\"\n",
    "    def add_noise(x, y):\n",
    "        noise = tf.random.normal(tf.shape(x), stddev=noise_factor)\n",
    "        x_noisy = x + noise\n",
    "        x_noisy = tf.clip_by_value(x_noisy, 0.0, 1.0)  # Assumendo dati normalizzati [0,1]\n",
    "        return x_noisy, y  # Input rumoroso, target pulito\n",
    "    \n",
    "    return ds_train.map(add_noise, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Per usare data augmentation:\n",
    "# ds_train = add_data_augmentation(ds_train, noise_factor=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1de9f",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49748932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBatch Norm, nel caso, va prima della layer activation)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Batch Norm, nel caso, va prima della layer activation)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b606e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec188c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# Setup logging e callbacks\n",
    "log_dir = \"logs/beta_vae/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,        # salva istogrammi dei pesi ogni epoca\n",
    "        write_graph=True,        # salva anche il grafo del modello\n",
    "        update_freq='epoch',     # ogni epoca\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_reconstruction_loss\",\n",
    "        patience=15,             # più pazienza con lr scheduling\n",
    "        min_delta=1e-5,          # soglia più stretta\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_reconstruction_loss',\n",
    "        factor=0.5,\n",
    "        patience=7,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'best_beta_vae_{latent_dim}d.keras',  # Nome più appropriato\n",
    "        monitor='val_reconstruction_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    BetaVAEMonitor()  # Rimosso il checkpoint duplicato\n",
    "]\n",
    "\n",
    "# Optimizer setup\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=1e-5, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999\n",
    ")\n",
    "\n",
    "# Creazione modello con beta migliorato\n",
    "beta_vae, encoder, decoder = build_asmsa_beta_vae(\n",
    "    n_features=feat.shape[1], \n",
    "    latent_dim=latent_dim,\n",
    "    beta=0.001  # ← CAMBIATO: da 0.01 a 0.1 per migliore qualità visiva\n",
    ")\n",
    "\n",
    "# Compilazione\n",
    "beta_vae.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528c260",
   "metadata": {},
   "source": [
    "tensorboard --logdir logs/autoencoder --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4fb0c-12b7-4b6d-a45f-da1111809ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47361719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 8.2265e-04 - loss: 0.0875 - reconstruction_loss: 0.0867\n",
      "Epoch 1: val_reconstruction_loss improved from inf to 0.06829, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - kl_loss: 8.2452e-04 - loss: 0.0875 - reconstruction_loss: 0.0867 - val_kl_loss: 0.0014 - val_loss: 0.0697 - val_reconstruction_loss: 0.0683 - learning_rate: 1.0000e-04\n",
      "Epoch 2/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0013 - loss: 0.0689 - reconstruction_loss: 0.0677\n",
      "Epoch 2: val_reconstruction_loss improved from 0.06829 to 0.06674, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0013 - loss: 0.0689 - reconstruction_loss: 0.0677 - val_kl_loss: 0.0011 - val_loss: 0.0678 - val_reconstruction_loss: 0.0667 - learning_rate: 1.0000e-04\n",
      "Epoch 3/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0011 - loss: 0.0675 - reconstruction_loss: 0.0664\n",
      "Epoch 3: val_reconstruction_loss improved from 0.06674 to 0.06575, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0011 - loss: 0.0675 - reconstruction_loss: 0.0664 - val_kl_loss: 0.0011 - val_loss: 0.0668 - val_reconstruction_loss: 0.0658 - learning_rate: 1.0000e-04\n",
      "Epoch 4/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0011 - loss: 0.0666 - reconstruction_loss: 0.0654\n",
      "Epoch 4: val_reconstruction_loss improved from 0.06575 to 0.06513, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0011 - loss: 0.0666 - reconstruction_loss: 0.0654 - val_kl_loss: 0.0012 - val_loss: 0.0663 - val_reconstruction_loss: 0.0651 - learning_rate: 1.0000e-04\n",
      "Epoch 5/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0012 - loss: 0.0662 - reconstruction_loss: 0.0650\n",
      "Epoch 5: val_reconstruction_loss improved from 0.06513 to 0.06446, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0012 - loss: 0.0662 - reconstruction_loss: 0.0650 - val_kl_loss: 0.0013 - val_loss: 0.0658 - val_reconstruction_loss: 0.0645 - learning_rate: 1.0000e-04\n",
      "Epoch 6/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0014 - loss: 0.0656 - reconstruction_loss: 0.0642\n",
      "Epoch 6: val_reconstruction_loss improved from 0.06446 to 0.06378, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0014 - loss: 0.0656 - reconstruction_loss: 0.0642 - val_kl_loss: 0.0015 - val_loss: 0.0652 - val_reconstruction_loss: 0.0638 - learning_rate: 1.0000e-04\n",
      "Epoch 7/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0651 - reconstruction_loss: 0.0636\n",
      "Epoch 7: val_reconstruction_loss improved from 0.06378 to 0.06355, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0651 - reconstruction_loss: 0.0636 - val_kl_loss: 0.0015 - val_loss: 0.0650 - val_reconstruction_loss: 0.0636 - learning_rate: 1.0000e-04\n",
      "Epoch 8/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0649 - reconstruction_loss: 0.0634\n",
      "Epoch 8: val_reconstruction_loss improved from 0.06355 to 0.06353, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0649 - reconstruction_loss: 0.0634 - val_kl_loss: 0.0014 - val_loss: 0.0649 - val_reconstruction_loss: 0.0635 - learning_rate: 1.0000e-04\n",
      "Epoch 9/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632\n",
      "Epoch 9: val_reconstruction_loss improved from 0.06353 to 0.06336, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632 - val_kl_loss: 0.0015 - val_loss: 0.0649 - val_reconstruction_loss: 0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 10/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632\n",
      "Epoch 10: val_reconstruction_loss did not improve from 0.06336\n",
      "\n",
      "Epoca 10: Beta=0.0010, KL=0.001496, Recon=0.063274\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632 - val_kl_loss: 0.0015 - val_loss: 0.0648 - val_reconstruction_loss: 0.0634 - learning_rate: 1.0000e-04\n",
      "Epoch 11/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632\n",
      "Epoch 11: val_reconstruction_loss improved from 0.06336 to 0.06324, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0632 - val_kl_loss: 0.0015 - val_loss: 0.0648 - val_reconstruction_loss: 0.0632 - learning_rate: 1.0000e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0631\n",
      "Epoch 12: val_reconstruction_loss improved from 0.06324 to 0.06318, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0647 - reconstruction_loss: 0.0631 - val_kl_loss: 0.0015 - val_loss: 0.0647 - val_reconstruction_loss: 0.0632 - learning_rate: 1.0000e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0015 - loss: 0.0646 - reconstruction_loss: 0.0631\n",
      "Epoch 13: val_reconstruction_loss improved from 0.06318 to 0.06310, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0015 - loss: 0.0646 - reconstruction_loss: 0.0631 - val_kl_loss: 0.0016 - val_loss: 0.0647 - val_reconstruction_loss: 0.0631 - learning_rate: 1.0000e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0016 - loss: 0.0646 - reconstruction_loss: 0.0630\n",
      "Epoch 14: val_reconstruction_loss improved from 0.06310 to 0.06307, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0016 - loss: 0.0646 - reconstruction_loss: 0.0630 - val_kl_loss: 0.0015 - val_loss: 0.0646 - val_reconstruction_loss: 0.0631 - learning_rate: 1.0000e-04\n",
      "Epoch 15/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 0.0016 - loss: 0.0645 - reconstruction_loss: 0.0629\n",
      "Epoch 15: val_reconstruction_loss improved from 0.06307 to 0.06263, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0016 - loss: 0.0645 - reconstruction_loss: 0.0629 - val_kl_loss: 0.0018 - val_loss: 0.0644 - val_reconstruction_loss: 0.0626 - learning_rate: 1.0000e-04\n",
      "Epoch 16/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0018 - loss: 0.0643 - reconstruction_loss: 0.0625\n",
      "Epoch 16: val_reconstruction_loss improved from 0.06263 to 0.06211, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0018 - loss: 0.0643 - reconstruction_loss: 0.0625 - val_kl_loss: 0.0019 - val_loss: 0.0641 - val_reconstruction_loss: 0.0621 - learning_rate: 1.0000e-04\n",
      "Epoch 17/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0020 - loss: 0.0638 - reconstruction_loss: 0.0618\n",
      "Epoch 17: val_reconstruction_loss improved from 0.06211 to 0.06143, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0020 - loss: 0.0638 - reconstruction_loss: 0.0618 - val_kl_loss: 0.0022 - val_loss: 0.0636 - val_reconstruction_loss: 0.0614 - learning_rate: 1.0000e-04\n",
      "Epoch 18/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0022 - loss: 0.0634 - reconstruction_loss: 0.0612\n",
      "Epoch 18: val_reconstruction_loss improved from 0.06143 to 0.06104, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0022 - loss: 0.0634 - reconstruction_loss: 0.0612 - val_kl_loss: 0.0022 - val_loss: 0.0633 - val_reconstruction_loss: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 19/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0023 - loss: 0.0633 - reconstruction_loss: 0.0610\n",
      "Epoch 19: val_reconstruction_loss improved from 0.06104 to 0.06074, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0023 - loss: 0.0633 - reconstruction_loss: 0.0610 - val_kl_loss: 0.0023 - val_loss: 0.0630 - val_reconstruction_loss: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 20/500\n",
      "\u001b[1m535/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0024 - loss: 0.0629 - reconstruction_loss: 0.0605\n",
      "Epoch 20: val_reconstruction_loss improved from 0.06074 to 0.06053, saving model to best_beta_vae_2d.keras\n",
      "\n",
      "Epoca 20: Beta=0.0010, KL=0.002370, Recon=0.060563\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0024 - loss: 0.0629 - reconstruction_loss: 0.0605 - val_kl_loss: 0.0024 - val_loss: 0.0629 - val_reconstruction_loss: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 21/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0024 - loss: 0.0627 - reconstruction_loss: 0.0603\n",
      "Epoch 21: val_reconstruction_loss improved from 0.06053 to 0.06037, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0024 - loss: 0.0627 - reconstruction_loss: 0.0603 - val_kl_loss: 0.0025 - val_loss: 0.0628 - val_reconstruction_loss: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 22/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0024 - loss: 0.0627 - reconstruction_loss: 0.0602\n",
      "Epoch 22: val_reconstruction_loss improved from 0.06037 to 0.06025, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0024 - loss: 0.0627 - reconstruction_loss: 0.0602 - val_kl_loss: 0.0025 - val_loss: 0.0627 - val_reconstruction_loss: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 23/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0025 - loss: 0.0627 - reconstruction_loss: 0.0602\n",
      "Epoch 23: val_reconstruction_loss improved from 0.06025 to 0.06016, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0025 - loss: 0.0627 - reconstruction_loss: 0.0602 - val_kl_loss: 0.0025 - val_loss: 0.0626 - val_reconstruction_loss: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 24/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0025 - loss: 0.0625 - reconstruction_loss: 0.0600\n",
      "Epoch 24: val_reconstruction_loss improved from 0.06016 to 0.06012, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0025 - loss: 0.0625 - reconstruction_loss: 0.0600 - val_kl_loss: 0.0025 - val_loss: 0.0626 - val_reconstruction_loss: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 25/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0025 - loss: 0.0625 - reconstruction_loss: 0.0600\n",
      "Epoch 25: val_reconstruction_loss improved from 0.06012 to 0.05999, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0025 - loss: 0.0625 - reconstruction_loss: 0.0600 - val_kl_loss: 0.0025 - val_loss: 0.0625 - val_reconstruction_loss: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 26/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0599\n",
      "Epoch 26: val_reconstruction_loss did not improve from 0.05999\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0599 - val_kl_loss: 0.0025 - val_loss: 0.0625 - val_reconstruction_loss: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 27/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0599\n",
      "Epoch 27: val_reconstruction_loss improved from 0.05999 to 0.05988, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0599 - val_kl_loss: 0.0026 - val_loss: 0.0624 - val_reconstruction_loss: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 28/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0599\n",
      "Epoch 28: val_reconstruction_loss improved from 0.05988 to 0.05975, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0025 - loss: 0.0624 - reconstruction_loss: 0.0598 - val_kl_loss: 0.0026 - val_loss: 0.0623 - val_reconstruction_loss: 0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 29/500\n",
      "\u001b[1m530/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0026 - loss: 0.0624 - reconstruction_loss: 0.0598\n",
      "Epoch 29: val_reconstruction_loss did not improve from 0.05975\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0026 - loss: 0.0624 - reconstruction_loss: 0.0598 - val_kl_loss: 0.0025 - val_loss: 0.0623 - val_reconstruction_loss: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 30/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0026 - loss: 0.0622 - reconstruction_loss: 0.0596\n",
      "Epoch 30: val_reconstruction_loss improved from 0.05975 to 0.05965, saving model to best_beta_vae_2d.keras\n",
      "\n",
      "Epoca 30: Beta=0.0010, KL=0.002587, Recon=0.059596\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0026 - loss: 0.0622 - reconstruction_loss: 0.0596 - val_kl_loss: 0.0026 - val_loss: 0.0622 - val_reconstruction_loss: 0.0597 - learning_rate: 1.0000e-04\n",
      "Epoch 31/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0026 - loss: 0.0621 - reconstruction_loss: 0.0594\n",
      "Epoch 31: val_reconstruction_loss improved from 0.05965 to 0.05954, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0026 - loss: 0.0621 - reconstruction_loss: 0.0594 - val_kl_loss: 0.0026 - val_loss: 0.0622 - val_reconstruction_loss: 0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 32/500\n",
      "\u001b[1m532/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0026 - loss: 0.0620 - reconstruction_loss: 0.0594\n",
      "Epoch 32: val_reconstruction_loss improved from 0.05954 to 0.05947, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0026 - loss: 0.0620 - reconstruction_loss: 0.0594 - val_kl_loss: 0.0026 - val_loss: 0.0621 - val_reconstruction_loss: 0.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 33/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0026 - loss: 0.0621 - reconstruction_loss: 0.0594\n",
      "Epoch 33: val_reconstruction_loss improved from 0.05947 to 0.05941, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - kl_loss: 0.0026 - loss: 0.0621 - reconstruction_loss: 0.0594 - val_kl_loss: 0.0026 - val_loss: 0.0620 - val_reconstruction_loss: 0.0594 - learning_rate: 1.0000e-04\n",
      "Epoch 34/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0027 - loss: 0.0619 - reconstruction_loss: 0.0592\n",
      "Epoch 34: val_reconstruction_loss improved from 0.05941 to 0.05931, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0027 - loss: 0.0619 - reconstruction_loss: 0.0592 - val_kl_loss: 0.0027 - val_loss: 0.0620 - val_reconstruction_loss: 0.0593 - learning_rate: 1.0000e-04\n",
      "Epoch 35/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0027 - loss: 0.0619 - reconstruction_loss: 0.0591\n",
      "Epoch 35: val_reconstruction_loss improved from 0.05931 to 0.05923, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0027 - loss: 0.0619 - reconstruction_loss: 0.0591 - val_kl_loss: 0.0027 - val_loss: 0.0619 - val_reconstruction_loss: 0.0592 - learning_rate: 1.0000e-04\n",
      "Epoch 36/500\n",
      "\u001b[1m536/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591\n",
      "Epoch 36: val_reconstruction_loss improved from 0.05923 to 0.05916, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591 - val_kl_loss: 0.0027 - val_loss: 0.0619 - val_reconstruction_loss: 0.0592 - learning_rate: 1.0000e-04\n",
      "Epoch 37/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591\n",
      "Epoch 37: val_reconstruction_loss improved from 0.05916 to 0.05911, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591 - val_kl_loss: 0.0027 - val_loss: 0.0618 - val_reconstruction_loss: 0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 38/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591\n",
      "Epoch 38: val_reconstruction_loss improved from 0.05911 to 0.05907, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0027 - loss: 0.0618 - reconstruction_loss: 0.0591 - val_kl_loss: 0.0027 - val_loss: 0.0618 - val_reconstruction_loss: 0.0591 - learning_rate: 1.0000e-04\n",
      "Epoch 39/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0617 - reconstruction_loss: 0.0589\n",
      "Epoch 39: val_reconstruction_loss improved from 0.05907 to 0.05896, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.0617 - reconstruction_loss: 0.0589 - val_kl_loss: 0.0028 - val_loss: 0.0617 - val_reconstruction_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 40/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0616 - reconstruction_loss: 0.0588\n",
      "Epoch 40: val_reconstruction_loss did not improve from 0.05896\n",
      "\n",
      "Epoca 40: Beta=0.0010, KL=0.002771, Recon=0.058856\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0028 - loss: 0.0616 - reconstruction_loss: 0.0588 - val_kl_loss: 0.0028 - val_loss: 0.0617 - val_reconstruction_loss: 0.0590 - learning_rate: 1.0000e-04\n",
      "Epoch 41/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0617 - reconstruction_loss: 0.0589\n",
      "Epoch 41: val_reconstruction_loss improved from 0.05896 to 0.05895, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.0617 - reconstruction_loss: 0.0589 - val_kl_loss: 0.0028 - val_loss: 0.0617 - val_reconstruction_loss: 0.0589 - learning_rate: 1.0000e-04\n",
      "Epoch 42/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0616 - reconstruction_loss: 0.0588\n",
      "Epoch 42: val_reconstruction_loss improved from 0.05895 to 0.05886, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0028 - loss: 0.0616 - reconstruction_loss: 0.0588 - val_kl_loss: 0.0028 - val_loss: 0.0617 - val_reconstruction_loss: 0.0589 - learning_rate: 1.0000e-04\n",
      "Epoch 43/500\n",
      "\u001b[1m536/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0614 - reconstruction_loss: 0.0586\n",
      "Epoch 43: val_reconstruction_loss improved from 0.05886 to 0.05879, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.0614 - reconstruction_loss: 0.0586 - val_kl_loss: 0.0028 - val_loss: 0.0616 - val_reconstruction_loss: 0.0588 - learning_rate: 1.0000e-04\n",
      "Epoch 44/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0587\n",
      "Epoch 44: val_reconstruction_loss improved from 0.05879 to 0.05876, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0587 - val_kl_loss: 0.0028 - val_loss: 0.0616 - val_reconstruction_loss: 0.0588 - learning_rate: 1.0000e-04\n",
      "Epoch 45/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0586\n",
      "Epoch 45: val_reconstruction_loss did not improve from 0.05876\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0586 - val_kl_loss: 0.0028 - val_loss: 0.0616 - val_reconstruction_loss: 0.0588 - learning_rate: 1.0000e-04\n",
      "Epoch 46/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0586\n",
      "Epoch 46: val_reconstruction_loss improved from 0.05876 to 0.05866, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0028 - loss: 0.0615 - reconstruction_loss: 0.0586 - val_kl_loss: 0.0028 - val_loss: 0.0615 - val_reconstruction_loss: 0.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 47/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0614 - reconstruction_loss: 0.0586\n",
      "Epoch 47: val_reconstruction_loss did not improve from 0.05866\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0029 - loss: 0.0614 - reconstruction_loss: 0.0586 - val_kl_loss: 0.0028 - val_loss: 0.0616 - val_reconstruction_loss: 0.0588 - learning_rate: 1.0000e-04\n",
      "Epoch 48/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0585\n",
      "Epoch 48: val_reconstruction_loss did not improve from 0.05866\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0585 - val_kl_loss: 0.0029 - val_loss: 0.0615 - val_reconstruction_loss: 0.0587 - learning_rate: 1.0000e-04\n",
      "Epoch 49/500\n",
      "\u001b[1m529/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584\n",
      "Epoch 49: val_reconstruction_loss improved from 0.05866 to 0.05857, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584 - val_kl_loss: 0.0029 - val_loss: 0.0615 - val_reconstruction_loss: 0.0586 - learning_rate: 1.0000e-04\n",
      "Epoch 50/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584\n",
      "Epoch 50: val_reconstruction_loss improved from 0.05857 to 0.05854, saving model to best_beta_vae_2d.keras\n",
      "\n",
      "Epoca 50: Beta=0.0010, KL=0.002886, Recon=0.058437\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584 - val_kl_loss: 0.0029 - val_loss: 0.0614 - val_reconstruction_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 51/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584\n",
      "Epoch 51: val_reconstruction_loss improved from 0.05854 to 0.05849, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0613 - reconstruction_loss: 0.0584 - val_kl_loss: 0.0029 - val_loss: 0.0614 - val_reconstruction_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 52/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583\n",
      "Epoch 52: val_reconstruction_loss did not improve from 0.05849\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583 - val_kl_loss: 0.0029 - val_loss: 0.0614 - val_reconstruction_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 53/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583\n",
      "Epoch 53: val_reconstruction_loss improved from 0.05849 to 0.05846, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583 - val_kl_loss: 0.0029 - val_loss: 0.0614 - val_reconstruction_loss: 0.0585 - learning_rate: 1.0000e-04\n",
      "Epoch 54/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583\n",
      "Epoch 54: val_reconstruction_loss improved from 0.05846 to 0.05839, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0583 - val_kl_loss: 0.0030 - val_loss: 0.0613 - val_reconstruction_loss: 0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 55/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - kl_loss: 0.0029 - loss: 0.0611 - reconstruction_loss: 0.0582\n",
      "Epoch 55: val_reconstruction_loss improved from 0.05839 to 0.05833, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0029 - loss: 0.0611 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0030 - val_loss: 0.0613 - val_reconstruction_loss: 0.0583 - learning_rate: 1.0000e-04\n",
      "Epoch 56/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0582\n",
      "Epoch 56: val_reconstruction_loss did not improve from 0.05833\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0030 - val_loss: 0.0614 - val_reconstruction_loss: 0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 57/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0582\n",
      "Epoch 57: val_reconstruction_loss improved from 0.05833 to 0.05832, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0029 - loss: 0.0612 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0030 - val_loss: 0.0613 - val_reconstruction_loss: 0.0583 - learning_rate: 1.0000e-04\n",
      "Epoch 58/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581\n",
      "Epoch 58: val_reconstruction_loss improved from 0.05832 to 0.05832, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581 - val_kl_loss: 0.0029 - val_loss: 0.0612 - val_reconstruction_loss: 0.0583 - learning_rate: 1.0000e-04\n",
      "Epoch 59/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0612 - reconstruction_loss: 0.0582\n",
      "Epoch 59: val_reconstruction_loss did not improve from 0.05832\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - kl_loss: 0.0030 - loss: 0.0612 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0029 - val_loss: 0.0613 - val_reconstruction_loss: 0.0583 - learning_rate: 1.0000e-04\n",
      "Epoch 60/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581\n",
      "Epoch 60: val_reconstruction_loss did not improve from 0.05832\n",
      "\n",
      "Epoca 60: Beta=0.0010, KL=0.002968, Recon=0.058139\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581 - val_kl_loss: 0.0029 - val_loss: 0.0613 - val_reconstruction_loss: 0.0584 - learning_rate: 1.0000e-04\n",
      "Epoch 61/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0612 - reconstruction_loss: 0.0582\n",
      "Epoch 61: val_reconstruction_loss improved from 0.05832 to 0.05817, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0612 - reconstruction_loss: 0.0582 - val_kl_loss: 0.0030 - val_loss: 0.0612 - val_reconstruction_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 62/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580\n",
      "Epoch 62: val_reconstruction_loss did not improve from 0.05817\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0030 - val_loss: 0.0612 - val_reconstruction_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 63/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580\n",
      "Epoch 63: val_reconstruction_loss did not improve from 0.05817\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0030 - val_loss: 0.0612 - val_reconstruction_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 64/500\n",
      "\u001b[1m545/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579\n",
      "Epoch 64: val_reconstruction_loss improved from 0.05817 to 0.05810, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579 - val_kl_loss: 0.0031 - val_loss: 0.0612 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 65/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581\n",
      "Epoch 65: val_reconstruction_loss did not improve from 0.05810\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0581 - val_kl_loss: 0.0030 - val_loss: 0.0612 - val_reconstruction_loss: 0.0582 - learning_rate: 1.0000e-04\n",
      "Epoch 66/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580\n",
      "Epoch 66: val_reconstruction_loss improved from 0.05810 to 0.05808, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0030 - val_loss: 0.0611 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 67/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580\n",
      "Epoch 67: val_reconstruction_loss improved from 0.05808 to 0.05806, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0031 - val_loss: 0.0611 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 68/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580\n",
      "Epoch 68: val_reconstruction_loss did not improve from 0.05806\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0610 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0030 - val_loss: 0.0611 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 69/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0580\n",
      "Epoch 69: val_reconstruction_loss did not improve from 0.05806\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0611 - reconstruction_loss: 0.0580 - val_kl_loss: 0.0030 - val_loss: 0.0611 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 70/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579\n",
      "Epoch 70: val_reconstruction_loss improved from 0.05806 to 0.05799, saving model to best_beta_vae_2d.keras\n",
      "\n",
      "Epoca 70: Beta=0.0010, KL=0.003028, Recon=0.057914\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579 - val_kl_loss: 0.0031 - val_loss: 0.0611 - val_reconstruction_loss: 0.0580 - learning_rate: 1.0000e-04\n",
      "Epoch 71/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579\n",
      "Epoch 71: val_reconstruction_loss improved from 0.05799 to 0.05797, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0580 - learning_rate: 1.0000e-04\n",
      "Epoch 72/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0578\n",
      "Epoch 72: val_reconstruction_loss did not improve from 0.05797\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0030 - val_loss: 0.0611 - val_reconstruction_loss: 0.0581 - learning_rate: 1.0000e-04\n",
      "Epoch 73/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579\n",
      "Epoch 73: val_reconstruction_loss did not improve from 0.05797\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0579 - val_kl_loss: 0.0030 - val_loss: 0.0611 - val_reconstruction_loss: 0.0580 - learning_rate: 1.0000e-04\n",
      "Epoch 74/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0610 - reconstruction_loss: 0.0579\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 74: val_reconstruction_loss did not improve from 0.05797\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0610 - reconstruction_loss: 0.0579 - val_kl_loss: 0.0030 - val_loss: 0.0610 - val_reconstruction_loss: 0.0580 - learning_rate: 1.0000e-04\n",
      "Epoch 75/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0578\n",
      "Epoch 75: val_reconstruction_loss improved from 0.05797 to 0.05796, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0030 - loss: 0.0609 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0030 - val_loss: 0.0610 - val_reconstruction_loss: 0.0580 - learning_rate: 5.0000e-05\n",
      "Epoch 76/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0577\n",
      "Epoch 76: val_reconstruction_loss improved from 0.05796 to 0.05792, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 77/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0609 - reconstruction_loss: 0.0578\n",
      "Epoch 77: val_reconstruction_loss improved from 0.05792 to 0.05791, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0609 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 78/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0609 - reconstruction_loss: 0.0578\n",
      "Epoch 78: val_reconstruction_loss did not improve from 0.05791\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0609 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 79/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 79: val_reconstruction_loss improved from 0.05791 to 0.05788, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 80/500\n",
      "\u001b[1m537/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 80: val_reconstruction_loss improved from 0.05788 to 0.05785, saving model to best_beta_vae_2d.keras\n",
      "\n",
      "Epoca 80: Beta=0.0010, KL=0.003080, Recon=0.057731\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 81/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 81: val_reconstruction_loss did not improve from 0.05785\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 82/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578\n",
      "Epoch 82: val_reconstruction_loss did not improve from 0.05785\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 83/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578\n",
      "Epoch 83: val_reconstruction_loss improved from 0.05785 to 0.05785, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 5.0000e-05\n",
      "Epoch 84/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578\n",
      "Epoch 84: val_reconstruction_loss did not improve from 0.05785\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0578 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 85/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 85: val_reconstruction_loss improved from 0.05785 to 0.05783, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 5.0000e-05\n",
      "Epoch 86/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 86: val_reconstruction_loss did not improve from 0.05783\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0579 - learning_rate: 5.0000e-05\n",
      "Epoch 87/500\n",
      "\u001b[1m544/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 87: val_reconstruction_loss did not improve from 0.05783\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 5.0000e-05\n",
      "Epoch 88/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 88: val_reconstruction_loss improved from 0.05783 to 0.05782, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 89/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 89: val_reconstruction_loss improved from 0.05782 to 0.05781, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 90/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 90: val_reconstruction_loss did not improve from 0.05781\n",
      "\n",
      "Epoca 90: Beta=0.0010, KL=0.003120, Recon=0.057635\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0610 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 91/500\n",
      "\u001b[1m543/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0606 - reconstruction_loss: 0.0575\n",
      "Epoch 91: val_reconstruction_loss improved from 0.05781 to 0.05778, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0606 - reconstruction_loss: 0.0575 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 92/500\n",
      "\u001b[1m535/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 92: val_reconstruction_loss did not improve from 0.05778\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 93/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 93: val_reconstruction_loss improved from 0.05778 to 0.05778, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 94/500\n",
      "\u001b[1m541/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 94: val_reconstruction_loss did not improve from 0.05778\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0578 - learning_rate: 2.5000e-05\n",
      "Epoch 95/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0576\n",
      "Epoch 95: val_reconstruction_loss improved from 0.05778 to 0.05773, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0577 - learning_rate: 1.2500e-05\n",
      "Epoch 96/500\n",
      "\u001b[1m539/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 96: val_reconstruction_loss did not improve from 0.05773\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0577 - learning_rate: 1.2500e-05\n",
      "Epoch 97/500\n",
      "\u001b[1m538/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0606 - reconstruction_loss: 0.0575\n",
      "Epoch 97: val_reconstruction_loss did not improve from 0.05773\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0606 - reconstruction_loss: 0.0575 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0577 - learning_rate: 1.2500e-05\n",
      "Epoch 98/500\n",
      "\u001b[1m542/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 98: val_reconstruction_loss did not improve from 0.05773\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0609 - val_reconstruction_loss: 0.0577 - learning_rate: 1.2500e-05\n",
      "Epoch 99/500\n",
      "\u001b[1m540/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576\n",
      "Epoch 99: val_reconstruction_loss improved from 0.05773 to 0.05772, saving model to best_beta_vae_2d.keras\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - kl_loss: 0.0031 - loss: 0.0607 - reconstruction_loss: 0.0576 - val_kl_loss: 0.0031 - val_loss: 0.0608 - val_reconstruction_loss: 0.0577 - learning_rate: 1.2500e-05\n",
      "Epoch 100/500\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - kl_loss: 0.0031 - loss: 0.0608 - reconstruction_loss: 0.0577"
     ]
    }
   ],
   "source": [
    "beta_vae.fit(ds_train, epochs=500, validation_data=ds_val, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5dd8a",
   "metadata": {},
   "source": [
    "# Decode and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a36f68-4599-4f52-aca9-b3f5bed65c39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate class 'BetaVAE'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'vae', 'class_name': 'BetaVAE', 'config': {'name': 'beta_vae', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'BetaVAE', 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'AdamW', 'config': {'name': 'adamw', 'learning_rate': 2.499999936844688e-05, 'weight_decay': 1e-05, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': None, 'loss_weights': None, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m----> 3\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_beta_vae_2d.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m encoder \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m decoder \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_api.py:187\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    195\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:365\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:442\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    440\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 442\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    447\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:431\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 431\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:694\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/saving/serialization_lib.py:812\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 812\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure custom classes are decorated with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not locate class 'BetaVAE'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'vae', 'class_name': 'BetaVAE', 'config': {'name': 'beta_vae', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'BetaVAE', 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'AdamW', 'config': {'name': 'adamw', 'learning_rate': 2.499999936844688e-05, 'weight_decay': 1e-05, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': None, 'loss_weights': None, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': True}}"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder = load_model(f'best_beta_vae_2d.keras')\n",
    "encoder = autoencoder.get_layer(\"encoder\")\n",
    "decoder = autoencoder.get_layer(\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73e3af-d99f-4884-bf9d-3887b5a60ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_latent_space(latent_dim, encoder, dataset, conf, target, cmap='rainbow', figsize=(8,8)):\n",
    "    \"\"\"\n",
    "    Computes latent embeddings and plots them in 2D.\n",
    "\n",
    "    Args:\n",
    "        encoder: the encoder model returning [z_mean, z_log_var, z]\n",
    "        dataset: input data or tf.data.Dataset yielding inputs (and optionally labels)\n",
    "        labels: optional array-like of same length as dataset for coloring\n",
    "        cmap: matplotlib colormap\n",
    "        figsize: tuple for figure size\n",
    "    \"\"\"\n",
    "    # Get embeddings\n",
    "    results = encoder.predict(dataset)\n",
    "    # results = [z_mean, z_log_var, z]\n",
    "    emb = np.array(results[2])  # results[2] use sampled z; shape (N,2)\n",
    "\n",
    "    rms_ref = md.load_pdb(conf)\n",
    "    rms_ref_bb   = rms_ref.atom_slice(bb_indices)\n",
    "    rms_tr = md.load_xtc(tr, top=rms_ref)\n",
    "    rmsd = md.rmsd(rms_tr, rms_ref)\n",
    "\n",
    "    #z = np.random.normal(loc=0.0, scale=1.0, size=(latent_dim,))\n",
    "\n",
    "    dists = np.linalg.norm(emb - target, axis=1)\n",
    "    # 4a. Se vuoi, ad esempio, le K righe più vicine:\n",
    "    K = 1\n",
    "    idx_closest = np.argsort(dists)[:K]\n",
    "    sample = emb[idx_closest].reshape(1, latent_dim)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.scatter(emb[:,0], emb[:,1], c=rmsd,s=0.5, cmap=cmap)\n",
    "    plt.scatter(sample[:,0], sample[:,1], marker=\"X\", c=\"Black\")\n",
    "\n",
    "    plt.show()\n",
    "    return emb, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2019c-5f03-4026-905a-dc540689abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array([-3,0]).reshape(1, 2)\n",
    "emb, sample = plot_latent_space(latent_dim, encoder, ds_all, conf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1941133-5a13-4f91-9460-bb803001b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape\n",
    "\n",
    "rms_ref = md.load_pdb(conf)\n",
    "rms_ref_bb   = rms_ref.atom_slice(bb_indices)\n",
    "rms_tr = md.load_xtc(tr, top=rms_ref)\n",
    "rmsd = md.rmsd(rms_tr, rms_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ab5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = decoder.predict(sample)\n",
    "s_orig = scaler.inverse_transform(s)\n",
    "\n",
    "coords_flat = s_orig[0, :coords.shape[1]]                    \n",
    "coords_recons = coords_flat.reshape((n_bb, 3))\n",
    "\n",
    "new_traj = md.Trajectory(\n",
    "    xyz=np.array([coords_recons]),     \n",
    "    topology=rms_ref_bb.topology     \n",
    ")\n",
    "\n",
    "\n",
    "new_traj.save_pdb(\"reconstructed.pdb\")\n",
    "\n",
    "import nglview as nv\n",
    "\n",
    "view = nv.show_file('reconstructed.pdb')\n",
    "view.clear_representations()\n",
    "view.add_line() \n",
    "#view.add_cartoon()\n",
    "view.center()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be6feb-d0a6-4ddf-904b-046708791eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfed4e-e675-419a-8f30-d5f99486699c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
